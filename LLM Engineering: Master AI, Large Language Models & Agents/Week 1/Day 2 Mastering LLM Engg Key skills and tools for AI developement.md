## **Frontier Models Overview**  
### **Closed-Source Frontier Models**  
- **GPT** â€“ OpenAI  
- **Claude** â€“ Anthropic  
- **Gemini** â€“ Google  
- **Command R** â€“ Cohere  
- **Perplexity** â€“ Perplexity AI  

### **Open-Source Frontier Models**  
- **Llama** â€“ Meta  
- **Mistral** â€“ Mistral AI  
- **Qwen** â€“ Alibaba Cloud  
- **Gemma** â€“ Google  
- **Phi** â€“ Microsoft  

---

## **Three Ways to Use Large Language Models (LLMs)**  
1ï¸âƒ£ **Chat Interface**  
   - Example: ChatGPT  

2ï¸âƒ£ **Cloud API (LLM APIs)**  
   - Frameworks: LangChain  
   - Managed AI Cloud Services:  
     - Amazon Bedrock  
     - Google Vertex AI  
     - Azure ML  

3ï¸âƒ£ **Direct Interface (Running Locally)**  
   - Via Hugging Face **Transformers** library  
   - Using **Ollama**  

---

## **How to Use Ollama with a Local LLM Interface**  
### **Setup Steps**  
1. **Install Ollama** and start it  
   - Check **localhost:11424**  
   - If needed, run: `ollama server`  
2. **Import necessary libraries**  
3. **Set up constants**  

### **Demo Code for a Question-Answering Pipeline**  
```python
from transformers import pipeline

# Load the QA pipeline
qa_pipeline = pipeline("question-answering", model="deepset/roberta-base-squad2")

# Define the context and question
context = "The Transformer model was introduced in a paper called 'Attention Is All You Need' by Vaswani et al. in 2017."
question = "Who introduced the Transformer model?"

# Get the answer
answer = qa_pipeline(question=question, context=context)
print("Answer:", answer["answer"])
```

---

## **LLM Capabilities**  
âœ”ï¸ **Question Answering (QA)**  
âœ”ï¸ **Text Summarization**  
âœ”ï¸ **Code Generation**  
âœ”ï¸ **Reasoning & Logical Analysis**  
âœ”ï¸ **Classification**  

---

## **Prompting Techniques**  
ğŸ”¹ **Zero-shot prompting**  
ğŸ”¹ **Few-shot prompting**  
ğŸ”¹ **Chain of Thought (CoT)**  
ğŸ”¹ **Role-based prompting** â€“ Behave as an **engineer**, **doctor**, etc.  
ğŸ”¹ **Prompt chaining**  

---

## **LangChain Framework**  
LangChain is a framework that simplifies the process of building applications powered by large language models (LLMs).  

---

## **Toolchains & Orchestration**  
ğŸ›  **Retrieval-Augmented Generation (RAG)**  
ğŸ›  **Microsoft 365 Copilot**  
ğŸ›  **Agentic AI**  

---

## **Performance of Frontier Models**  
âœ”ï¸ **Synthesizing Information**  
âœ”ï¸ **Expanding on Skeleton Ideas**  
âœ”ï¸ **Coding & Development**  

### **Limitations**  
âš ï¸ **Struggles in Specialized Domains**  
âš ï¸ **Lacks Knowledge of Recent Events**  
âš ï¸ **Can Make Confident Mistakes**  

---

 
